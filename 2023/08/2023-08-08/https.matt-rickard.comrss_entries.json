[{"source": "https://matt-rickard.com/rss", "title": "A Fine-Tuning Marketplace", "description": "What if there was a world where thousands of small models ruled instead of ChatGPT? What if there was a way to quickly and easily share different styles of models \u2014 for specific tasks, styles, or data?\n\nLoRA (Low-Rank Adaptation of Large Language Models) is a fine-tuning strategy that trains relatively quickly and can be applied just with model weight deltas (i.e., small file size). It\u2019s mainly used for image diffusion models (but can also translate to text-generation LLMs).\n\nSeveral websites ha", "link": "https://matt-rickard.com/a-fine-tuning-marketplace", "date_published": "2023-08-08T13:30:53+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}]