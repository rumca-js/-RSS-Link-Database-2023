# Source:Matt Rickard, URL:https://matt-rickard.com/rss, language:en-US

## Deterministic, Structured LLM Output
 - [https://matt-rickard.com/structured-llm-output](https://matt-rickard.com/structured-llm-output)
 - RSS feed: https://matt-rickard.com/rss
 - date published: 2023-08-10T13:30:13+00:00

How do you consume text generated by LLMs with code? You might try prompt engineering to “format the answer in JSON”, but that won’t work all the time. Or you might try a variety of tricks to extract the answer or the field out of the text generation, but that’s also prone to error.

I’m launching another API on thiggle that lets you perform text generation with LLMs but with generated tokens conforming to regex patterns. That means that you can easily specify the shape of outputs — are they alp

