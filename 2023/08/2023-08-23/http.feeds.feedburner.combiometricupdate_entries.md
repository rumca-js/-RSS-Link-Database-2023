# Source:Biometric Update, URL:http://feeds.feedburner.com/biometricupdate, language:en-US

## Settlement of BIPA suit against Clearview AI could be days away
 - [https://www.biometricupdate.com/202308/settlement-of-bipa-suit-against-clearview-ai-could-be-days-away](https://www.biometricupdate.com/202308/settlement-of-bipa-suit-against-clearview-ai-could-be-days-away)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T22:21:17.540267+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1365" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/07111707/black-woman-facial-recognition-scaled.jpg" width="2048" />
		A settlement in a U.S. biometric data privacy case involving Clearview AI and other business defendants could be finalized inside a week, according to court documents seen by <em>Biometric Update</em>.

A putative class action alleging that online face photo-scraper <a href="https://www.biometricupdate.com/companies/clearview-ai">Clearview</a> and national retailer Macy's violated the state of Illinois' Biometric Information Privacy Act has idled for a number of weeks.

The lead plaintiffs and defendants have worked with a mediator to find an acceptable resolution separate from the <a href="https://www.troutman.com/a/web/280464/BIOMETRICS-SECTION-1st-BULLET-ClearviewAIPrelimInj.pdf">contentious</a> case (1:21CV00135) in the U.S. District Court for northeastern Illinois.

Both sides have submitted to Judge Sharon Johnson Coleman a joint status report indicating that after working through "numerous" settlement drafts, they have arrived at a mutually acceptable framework for a settlement, first reported by <a href="https://www.mediapost.com/publications/article/388461/clearview-ai-nears-settlement-in-privacy-battle-ov.html">MediaPost</a>.

Lawyers for each side were to have met August 22 with Coleman to answer her questions about the proposed agreement, the next step in getting the judge to approve the settlement and end the case. It's not known on deadline if the meeting took place.

The case involves at least nine named plaintiffs, six in New York and three in Illinois. The cases were consolidated and heard in Illinois.

Clearview is alleged to have broken Illinois law by not getting the plaintiffs' consent before collecting their biometric identifiers. They also, according to court documents, broke biometric privacy laws in Virginia, New York and California.

Macy's is named in the class action because it reportedly used Clearview facial recognition algorithms without getting subjects' consent. The retail chain alleged collected security video images of <a href="https://www.cincinnati.com/story/news/2020/08/07/macys-faces-class-action-lawsuit-use-facial-recognition-software-clearview-ai/3315099001/">6,000 people</a> in its stores for comparison with the billions of face scans collected by Clearview, according to regional newspaper The Cincinnati Enquirer.

Settlement is apparently an attractive option in <a href="https://www.biometricupdate.com/202308/bnsf-rail-asks-to-settle-or-retry-its-bipa-damage-award">another BIPA case</a>, this one involving BNSF Railway.

## Here’s the newest camera hack fraudsters are using to beat facial recognition
 - [https://www.biometricupdate.com/202308/heres-the-newest-camera-hack-fraudsters-are-using-to-beat-facial-recognition](https://www.biometricupdate.com/202308/heres-the-newest-camera-hack-fraudsters-are-using-to-beat-facial-recognition)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T22:21:17.538379+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1365" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/02/22111201/face-biometric-enrollment-scaled.jpg" width="2048" />
		<em>By Stuart Wells, Chief Technology Officer at </em><a href="https://www.jumio.com"><em>Jumio</em></a>

As organizations have tried to stay ahead of cybercriminals, faces and other biometrics have become the passwords for so many everyday functions. From unlocking a phone, to accessing a bank account, to setting up a doctor’s appointment, important tasks are completed by verifying that the correct face is the one behind (or in front of) the camera.

However, like with traditional passwords, fraudsters have gotten creative about getting around facial recognition security. By now, most everyone understands deepfakes and the threats associated with them. Since, by definition, a deepfake is an altered or fabricated video sequence, cybercriminals depend on a technique known as “camera injection” to beat facial recognition systems.

Some experts have <a href="https://www.europol.europa.eu/cms/sites/default/files/documents/Europol_Innovation_Lab_Facing_Reality_Law_Enforcement_And_The_Challenge_Of_Deepfakes.pdf">predicted</a> that as much as 90 percent of content on the web could be synthetically generated by 2026, making it increasingly difficult for organizations to discern which users are who they claim to be. Here is a rundown on how fraudsters are pulling off camera injection attacks, what makes it so dangerous and how organizations can protect themselves.
<h2>How do camera injection attacks work?</h2>
As passwords have evolved beyond numerical and alphabetical characters, hackers have been pushed to adapt beyond the likes of brute force attacks and credential stuffing. Beating facial recognition software requires a far greater level of sophistication, which has led to the invention of tactics designed to trick biometric and liveness detection tools.

Fraudsters introduce deepfake videos into the system using a camera <a href="https://www.biometricupdate.com/tag/injection-attacks">injection attack</a>. Camera injection occurs when a fraudster bypasses the charged-coupled device (CCD) of a camera to inject pre-recorded content, a real-time face swap video stream or completely fabricated (deepfake) content. This pre-recorded content could be an unaltered video of a real person that a bad actor is attempting to defraud. The pre-recorded or real-time generated video could be a clip where the face is altered in some way, or of a completely synthetic face that does not exist.

The bypass of a live feed that a real camera’s CCD would normally capture is accomplished through a couple of methods. One is by hacking the device driver of a real camera and injecting the video stream into a lower level of the device driver. The more common means of camera injection is to have a virtual camera device driver that simply feeds a pre-recorded or real-time generated video stream to the system, presenting it as a real camera feed.

Since a video is a series of still images, a fraudster will sometimes feed the same image into every frame of a video stream. The result is a video stream where there is no motion. A more sophisticated technique, but also more time-intensive for the fraudsters, is altering or fabricating a video sequence where motion is present. The most sophisticated technique is where a deepfake can be manipulated in real time to perform actions asked for by the integrated data viewer system.
<h2>What is the threat?</h2>
Once an attacker has successfully passed through this stage of verification, they will have access to an account that is not theirs, leaving them free to wreak havoc under a synthetic or stolen identity. From there, malicious actors can register for phony accounts, complete fraudulent transactions and more.

The primary concern with the camera injection technique is that, if done successfully, organizations will not realize they have been beaten. If the facial recognition technology in place believes it has properly verified a user’s identity when it has actually been fooled by camera injection, fraudsters can essentially sneak in undetected.

Only when an account conducts some kind of suspicious behavior, like an unusual bank transaction, would an organization determine that they may have fallen victim to this kind of attack. In many cases, by the time an organization detects the threat, the damage to a user’s account has already been done.
<h2>Can camera injection attacks be prevented?</h2>
While fraudsters’ tactics continue to evolve, so do the mechanisms designed to keep them out. Robust identity verification with sophisticated liveness detection tools can protect organizations from fraudsters employing the camera injection technique.

To defend against this type of tactic, organizations can establish controls to detect when a camera device driver has been compromised, when a virtual camera is being used and/or when forensic evaluation of a video stream reveals manipulation or fabrication.

Comparing natural motion to the motions in the captured video can help reveal manipulation. Elements like eye motion, expression changes or regular blinking patterns occur naturally. If no such motion is detected, there is a high chance that a single image is being replayed to create a video sequence.

The capture process can also inject artifacts that should alter the captured images in ways that are detectable. Some of these could be changing the camera parameters (like ISO, aperture, frame rate, resolution, etc.) and observing whether the expected changes occur in the capture. Another could be changing the color or illumination intensity of the device's screen and looking for a corresponding reflection from the face being captured.

By relying on the accelerometer within the device used to take a verification selfie, and comparing it to the changes in the objects (e.g., face) captured during the video, organizations can determine whether a camera has been compromised by a potential hacker. The individual frames of the video can be forensically analyzed for signs of tampering, such as double compressed parts of the image, or for artifacts indicating a computer-generated (deepfake) image.
<h2>Living without fear of fraudsters</h2>
Facial recognition tools are meant to supply an added level of security for organizations, and the emergence of the camera injection technique has been a legitimate threat to that extra layer of protection.

A recent Jumio survey revealed that 52 percent of respondents <a href="https://www.jumio.com/2023-identity-study/">believe</a> they can accurately detect a deepfake video, but the reality is that synthetic content is growing more sophisticated and harder to decipher. In a recent <a href="https://www.channelnewsasia.com/business/deepfake-scam-china-fans-worries-over-ai-driven-fraud-3506361">incident</a> in China, an AI-powered video impersonator assumed the identity of the victim’s friend and scammed them out of more than $600,000.

As prevalent as the threat of synthetic content may be, sophisticated liveness detection during the identity verification process enables businesses to stay ahead of hackers attempting to use techniques like camera injection. With these resources at their disposal, organizations can feel confident that malicious actors are being kept at bay while ensuring legitimate business users can still gain entry to their accounts.
<h2>About the author</h2>
<strong> </strong>As Chief Technology Officer at <a href="https://www.biometricupdate.com/companies/jumio">Jumio</a>, Stuart is responsible for all aspects of Jumio’s innovation, machine learning and engineering. An industry veteran with more than 30 years of tech experience, Stuart previously was the chief product and technology officer at FICO and held executive positions at Avaya and Sun Microsystems.

<em>DISCLAIMER: Biometric Update’s Industry Insights are submitted content. The views expressed in this post are that of the author, and don’t necessarily reflect the views of Biometric Update.</em>

## Self-sovereign identity’s promise is big but so are its challenges
 - [https://www.biometricupdate.com/202308/self-sovereign-identitys-promise-is-big-but-so-are-its-challenges](https://www.biometricupdate.com/202308/self-sovereign-identitys-promise-is-big-but-so-are-its-challenges)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T20:21:14.605910+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1365" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/04/28130003/tablet-digital-identity-open-banking-scaled.jpg" width="2048" />
		Today’s consumers do not have much say in deciding the destiny of their data. They might not be able to define rules on data privacy, nor to decide how their data should be used by Google, Amazon and others.

Self-sovereign identity (SSI) could solve that issue by giving control over biometric data to consumers. A new paper <a href="https://dl.acm.org/doi/10.1145/3616400">published </a>by the Association for Computing Machinery (ACM) illustrates SSI’s place among other data-management concepts and its challenges.

Data sovereignty can be understood two ways -- people’s right to control their data and as data residency. In the first case, the authors propose that data be governed by the CARE principles for indigenous data governance and the FAIR principles.

CARE (collective benefit, authority to control, responsibility and ethics) is the first attempt to outline collective rights as part of the movement to open data in the context of the United Nations Declaration on the Rights of Indigenous Peoples. FAIR (findable, accessible, interoperable and reusable) principles were developed in the Netherlands in 2015 and have since become a way of sharing data that maximizes the use and re-use of data.

Data residency, on the other hand, is when a business or government specifies the geographical location of its data. The European Union’s General Data Protection Regulation (GDPR) includes data residence.

Another connected term is digital sovereignty, which is getting increasing attention in the context of control over digital assets. Digital sovereignty has been used to convey the idea that governments should reassert their authority over the internet and protect their citizens and businesses with regulations.

<a href="https://www.biometricupdate.com/tag/self-sovereign-identity">Self-sovereign identity</a> is a relatively new decentralized model that has the potential to solve the problems of digital identification and authentication and to give individuals full control of their digital identity, according to the ACM researchers.

Self-sovereign identities are supposed to provide a digital identity, prevent theft and fraud, assure privacy and help get rid of passwords. But it faces challenges.

Among them are challenges in decentralized identifiers, which are often related to the distribution of public keys, the security of users’ personal data and identities, the scalability and reliability of decentralized identifiers, which are commonly based on blockchains and on ensuring users can keep their identities private.

But there are issues beyond technical ones that SSIs have to solve, including standardization. The market is fragmented with legal and regulatory uncertainty. The research also lists relevant frameworks, policy and regulations connected to SSI.

A meta-analysis of research in the self-sovereign identity field shows that most papers focus either on the proof of concept or on the prototype implementation of the concept. Another portion of the research focuses on domains or industries where SSI solutions can be applied. This includes financial banking, education, certification, healthcare, transport, e-government and IoT.

The paper was written by Kheng Leong Tan, Chi-Hung Chi and Kwok-Yan Lam from the Nanyang Technological University in Singapore.

## GEDmatch loophole allows the police to access user DNA without their consent
 - [https://www.biometricupdate.com/202308/gedmatch-loophole-allows-the-police-to-access-user-dna-without-their-consent](https://www.biometricupdate.com/202308/gedmatch-loophole-allows-the-police-to-access-user-dna-without-their-consent)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T20:21:14.596604+00:00

<img alt="DNA" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1333" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2021/07/20165204/dna.jpg" width="2000" />
		On August 14th, DNA biometrics testing identified a body that was found on pilings in a Washington river a year ago, according to a release from the Cowlitz County Sheriff's Office. It was too decomposed to conduct facial recognition or take fingerprints, the <a href="https://www.tri-cityherald.com/news/state/washington/article278489234.html">Tri-City Herald</a> reports.

Investigators partnered with <a href="https://othram.com/">Othram</a>, a forensic genetic genealogy lab in Texas, which was able to identify the brother of the unidentified body. The brother confirmed the deceased man was 55-year old Bryan M. Heinrich Sr. based on a tattoo. While there was no foul play in this instance, the case raises questions about privacy concerns with the use of DNA databases in criminal investigations.

By using a privacy loophole in GEDmatch's services, Cece More, an actress and director-turned-genetic genealogist, worked with law enforcement agencies to use commercial DNA databases to help identify unknown human remains or perpetrators who left DNA at a crime scene, according to <a href="https://theintercept.com/2023/08/18/gedmatch-dna-police-forensic-genetic-genealogy/">The Intercept</a>.

Police and the genealogists working with them can access the loophole by manipulating search fields within a DNA comparison tool to show profiles of individuals who explicitly opted out of sharing their information with police.

Records of communications reveal that Moore, along with two other forensic genealogists discuss how to trigger the loophole, mentioning to hide that her organization made an identification using an opted-out profile.

Back in 2018 Joseph James DeAngelo, the Golden State Killer, was arrested after a broad, invasive search conducted without a warrant and in such a manner that it appeared to violate the privacy policy of at least one DNA company, according to the <a href="https://www.latimes.com/california/story/2020-12-08/man-in-the-window">LA times</a>.

Prosecutors claim to have used family tree searchers to find relatives of the killer to initially identify DeAngelo. Afterwards, a detective confirmed investigators uploaded semen from a rape kit to develop a DNA profile that was then uploaded to GEDmatch, an open-source platform.

Prosecutors did not share that the genetic material was first sent to FamilyTreeDNA, which allowed law enforcement to create a fake account and search for matching customers. After finding only distant leads, they uploaded the profile to MyHeritage where they identified a close relative who helped break the case.

After The Intercept initially shared its reporting on <a href="https://www.biometricupdate.com/202106/curbs-on-biometric-dna-searches-by-cops-not-a-trend-yet">GEDmatch</a>, Margaret Press, founder of the DNA Doe Project, released a statement.

“In hindsight, it’s clear we failed to consider the critically important need for the public to be able to trust that their DNA data will only be shared and used with their permission and under the restrictions they choose," she says.

"We should have reported these bugs to GEDmatch and stopped using the affected reports until the bugs were fixed," continues Press. "Instead, on that first day when we found that all of the profiles were set to opt-out, I discouraged our team from reporting them at all. I now know I was wrong and I regret my words and actions."

## Worldcoin biometrics collection faces more scrutiny in Kenya, skepticism in India
 - [https://www.biometricupdate.com/202308/worldcoin-biometrics-collection-faces-more-scrutiny-in-kenya-skepticism-in-india](https://www.biometricupdate.com/202308/worldcoin-biometrics-collection-faces-more-scrutiny-in-kenya-skepticism-in-india)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T20:21:14.595014+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="761" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/04/29155417/worldcoin-orb-indonesia.png" width="1422" />
		<a href="https://www.biometricupdate.com/companies/worldcoin">Worldcoin</a>, the project that wants to scan your iris biometrics in exchange for some of its cryptocurrency, continues to attract regulators in Kenya and skepticism in countries like India, which has just come out with its new data privacy law.

After Kenyan data protection authorities ordered Worldcoin to <a href="https://www.biometricupdate.com/202308/data-protection-authorities-in-kenya-argentina-investigating-worldcoin">suspend enrolments</a> earlier this month and <a href="https://www.biometricupdate.com/202308/worldcoin-biometric-enrollment-frenzy-sparks-raid-concerns">police raided</a> its offices in Nairobi, the East African country has formed a parliamentary committee to investigate the company’s operations.

The 15-member team, led by parliament member Gabriel Tongoyo, will have 42 days to submit its report. Other state agencies, including those covering security, protection and financial services, have started their own inquiries to establish the legality of Worldcoin’s operations, The Star <a href="https://www.the-star.co.ke/news/realtime/2023-08-21-parliament-forms-committee-to-investigate-worldcoin-project/">reports</a>.

The main issue troubling Kenyan regulators is Worldcoin’s plan to register citizens through the collection of iris data. Kenya’s Office of the Data Protection Commissioner (ODPC), which has been looking into the company since 2022, argues that the company is likely to violate the local Data Protection Act by handling user data, including iris and face biometrics.

The government is also facing pressure from rights organizations. Amnesty International and the Open Institute have expressed concern over the lack of information on security measures and the data collected.

“Preliminary statements from State agencies suggest a significant data breach in Kenya. We urgently call for thorough and independent investigations by the Data Commissioner,” the organizations say in a statement <a href="https://www.the-star.co.ke/news/realtime/2023-08-11-lobbyists-to-state-come-clear-on-protection-of-worldcoin-data/">published </a>by The Star.

The NGOs also called for clarifications on whether Worldcoin submitted a Data Protection Impact Assessment and whether the company obtained proper consent from its users. One of the criticisms the project has faced is that many people are lured by the promise of easy money in exchange for a quick eyeball scan and are not aware of <a href="https://www.biometricupdate.com/202308/worldcoin-biometric-enrollment-frenzy-sparks-raid-concerns">potential trade-offs</a> such as limited legal action against the company.

Alex Blania, a co-founder of Worldcoin, has defended the project aimed at providing each person in the world with digital IDs and financial services by emphasizing its commitment to privacy and security. But regulators in countries such as the UK, France and Germany – which has launched its own investigation – have been <a href="https://www.biometricupdate.com/202307/multiple-regulators-turn-gaze-to-worldcoins-iris-collection">turning their gaze</a> toward the crypto project. Its latest criticism comes from India.
<h2>India's new data law may not be enough to protect users from Worldcoin: Rights lawyer</h2>
The Indian Parliament has passed its new <a href="https://www.meity.gov.in/writereaddata/files/Digital%20Personal%20Data%20Protection%20Act%202023.pdf">Digital Personal Data Protection Act</a> with implementation expected within 10 months. The Act will affect Worldcoin’s plans to collect data from users in India but they may not be enough to guarantee accountability, Prasanna S., a lawyer at digital rights organization Article 21 Trust, <a href="https://www.medianama.com/2023/08/223-interview-advoc-prasanna-legality-worldcoins-operations-in-india/">explains</a> in an interview with tech outlet Medianama.

“We know the safeguards are not anywhere near the ideal that we want,” says Prasanna.

In India, it is legal to create a database of biometric data such as Worldcoin so long as it is optional and the consent is free and informed. Unless it can be established that significant harm was caused by the data collection activity, it’s going to be very difficult to move in a policy direction that prevents private companies from collecting biometric data, he notes.

This may present a problem: Unlike state projects such as India’s ID number Aadhaar which is closely followed by the public, with private projects that collect biometric data the regulatory regime is “very superficial.”

“It's not just a privacy-related concern,” says Prasanna. “When the work of private companies impacts fundamental rights or human rights users or citizens at large, what is the accountability?”

An <a href="https://www.medianama.com/2023/08/223-is-worldcoin-collection-of-biometric-data-legal-in-india/">analysis</a> by Medianama states that Worldcoin’s collection of user data in India appears to be legal.

India’s current data protection regime, dating from 2000, classifies bank details and biometric information as sensitive personal information. Companies need to disclose the purpose for which it has been collected while allowing people the option to delete or correct the data being collected.

Worldcoin defines a clear purpose for which it is collecting data – to prevent fraudulent users from signing up more than once – and offers a consent form explaining that the company will retain  unique iris code based on the image of the users’ irises obtained through their imaging device, the Orb.

## Walmart Spark delivery platform picks Persona selfie biometrics for driver verification
 - [https://www.biometricupdate.com/202308/walmart-spark-delivery-platform-picks-persona-selfie-biometrics-for-driver-verification](https://www.biometricupdate.com/202308/walmart-spark-delivery-platform-picks-persona-selfie-biometrics-for-driver-verification)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T20:21:14.593293+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1536" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/23153113/shutterstock_2188692801-scaled.jpg" width="2048" />
		Walmart delivery app Spark is implementing selfie biometrics checks from <a href="https://www.biometricupdate.com/companies/persona">Persona</a> for drivers to cut down on incidents of individuals using identity fraud to corner the market for delivery jobs.

The delivery platform has scaled quickly, with three times more drivers than a year ago, <a href="https://www.businessinsider.com/walmart-spark-delivery-app-multiple-accounts-names-verify-identity-2023-8">Business Insider</a> reports. Several drivers who spoke to Insider say that as that has happened, they have been given less orders to complete through the crowdsourced delivery app. Meanwhile, Walmart employees claim to have seen other drivers using multiple identities and multiple phones to get more work by gaming the system.

In response, Walmart is instituting identity verification through ID document photos and selfie biometrics. The <a href="https://drive4spark.walmart.com/spark-driver-privacy-statement">Spark driver app privacy statement</a> reveals that the technology is provided by Persona.

Previously, some stores had begun checking drivers’ physical IDs before releasing orders, but others said they were not allowed to do so. A Walmart spokesperson told Insider that the company takes reports of fraud seriously and that fraudulent accounts are deactivated whenever they are found through active monitoring.

The change seems to include not just onboarding but biometric authentication, with Insider reporting that verifications include periodic selfie requests. How frequent authentication will be required remains unclear, with reports of selfies requested for each delivery at one store early last week, and much less frequently by the end of the week.

Delivery platforms including <a href="https://www.biometricupdate.com/201904/amazon-secures-delivery-contractor-accounts-with-biometric-facial-verification">Amazon</a>, <a href="https://www.biometricupdate.com/202307/checkout-com-launches-selfie-biometrics-solution-for-seamless-customer-onboarding">Uber Eats</a> and <a href="https://www.biometricupdate.com/202109/persona-raises-150m-renews-development-efforts-in-digital-id-solutions-and-infrastructures">DoorDash</a> already use selfie biometrics and ID checks.

Persona has won several major contracts for biometric identity verification of late, the aforementioned DoorDash among them, along with online game <a href="https://www.biometricupdate.com/202306/persona-wins-major-gaming-client-as-age-verification-grows-up">Roblox</a>.

## Gov’ts debate AI rules but the results don’t command
 - [https://www.biometricupdate.com/202308/govts-debate-ai-rules-but-the-results-dont-command](https://www.biometricupdate.com/202308/govts-debate-ai-rules-but-the-results-dont-command)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T20:21:14.591448+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1152" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/02/14134710/facial-recogntiion-street-crowd-scaled.jpg" width="2048" />
		Leaders of Australia, Ireland, Israel, the United States and the Group of Seven (G7) finance ministers are seeking input on AI regulations, according to a <a href="https://www.reuters.com/technology/governments-race-regulate-ai-tools-2023-08-22/">handy guide</a> published by Reuters. The European Union, United Kingdom and United Nations are planning regulations while China has implemented temporary regulations.

And Italy, Japan, Spain and France are investigating possible data and privacy breaches involving AI.
<h2>AI measures an ‘urgent issue,’ says US policy advisor</h2>
The White House is considering many measures connected to regulating AI, but their timeline is uncertain, <a href="https://www.registercitizen.com/business/article/white-house-science-adviser-calls-for-more-18306270.php">according to</a> an Associated Press interview with Washington technology advisor Arati Prabhakar this week.

“The president has been clear that this is an urgent issue,” he reportedly told the AP. Prabhakar directs the White House Office of Science and Technology Policy.

His office is helping to shape the government's approach to AI, relying on cooperation with industry leaders. In July, seven companies, including Meta, Google, Microsoft and ChatGPT-maker <a href="https://www.biometricupdate.com/202307/chatgpt-facial-recognition-potential-makes-openai-nervous">OpenAI</a> agreed to meet voluntary AI safety standards set by the White House.

One of the issues being examined is the black-box development of most machine-learning code, said Prabhakar. But there are enough other AI concerns that some people worry that algorithms could become a djinn sprung loose from the bottle, with unexpected and possibly dangerous consequences.

For example, he said, “there’s now a fairly substantial, distressing history of facial recognition systems being used inappropriately and leading to <a href="https://www.biometricupdate.com/202308/black-woman-matched-by-facial-recognition-alleges-police-misconduct-in-lawsuit">wrongful arrests</a> of Black people."
<h2>Australian rights commission: We need our own AI Act</h2>
Commissioners are <a href="https://humanrights.gov.au/about/news/australia-needs-ai-regulation">warning</a> that the country urgently needs an AI Act similar to the one being meted out in the E.U.

They also are asking for a dedicated AI safety commissioner who would not have an enforcement role but who instead would assist regulators on the topic, InnovationAus.com <a href="https://www.innovationaus.com/ai-act-needed-to-protect-human-rights-hrc/?utm_medium=email&amp;utm_campaign=Newsletter1149-18August2023&amp;utm_content=Newsletter1149-18August2023+CID_fe33ff4661612d617ef308757a918011&amp;utm_source=Emailmarketingsoftware&amp;utm_term=AIActneededtoprotecthumanrightsHRC&amp;utm_term=AIActneededtoprotecthumanrightsHRC">reports</a>.

“If Australia is to reap the benefits of AI, it must ensure the technology is developed and used ethically,” says Rights Commissioner Lorraine Finlay.

The organization says it has submitted 47 recommendations to the Industry Department, noting that many issues complicating the use of AI could be resolved with improvements to legal frameworks including privacy laws.

In 2021, the commission published a report with similar recommendations. The organization had called on the government to halt use of facial recognition and other AI algorithms for important decisions until protections are in place. Its findings were largely ignored by the previous government, the report notes.

Australia is seeking input on regulations but that call has divided stakeholders. Some in industry want technology-neutral regulations while others are advocating more government intervention, according to the report.
<h2>Women AI ethics researchers are leading the call for regulation</h2>
As the debates on AI have grown during the past year, many creators of these algorithms have issued alarms about AI's effects on society .

Yet female AI-ethics researchers have been warning for years about the societal effects of AI systems and their problematic interactions with people of color and other marginalized communities.

In an <a href="https://www.rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/">interview</a> with culture and news publisher Rolling Stone, AI thought leaders such as <a href="https://www.biometricupdate.com/201907/buolamwini-gebru-and-raji-win-ai-innovation-award-for-research-into-biometric-bias">Timnit Gebru</a>, Safiya Noble, Rumman Chowdhury, Seeta Peña Gangadharan and Joy Buolamwini discussed how their findings on AI bias and other problems have often been dismissed.

<a href="https://www.biometricupdate.com/201907/buolamwini-gebru-and-raji-win-ai-innovation-award-for-research-into-biometric-bias">Buolamwini’</a>s Algorithmic Justice League has been looking into reported harms caused by the Transportation Security Administration's expanded use of face biometrics to 25 airports across the U.S. The computer scientist and digital activist with the MIT Media Lab was invited this summer to speak to President Joe Biden at a closed-door roundtable on AI.

Ethically training AI is crucial, she says, while treating the algorithms like ordinary code could pose dire consequences.

## MOSIP implementation pilot with BioEnable biometrics nears successful completion
 - [https://www.biometricupdate.com/202308/mosip-implementation-pilot-with-bioenable-biometrics-nears-successful-completion](https://www.biometricupdate.com/202308/mosip-implementation-pilot-with-bioenable-biometrics-nears-successful-completion)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T18:41:11.900019+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1537" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/06/20161235/mosip_compliant-scaled.jpg" width="2048" />
		A pilot implementation of the <a href="https://www.biometricupdate.com/companies/mosip-modular-open-source-identification-platform">MOSIP</a> digital identity platform is nearing completion in Burkina Faso using biometric devices and software from <a href="https://www.biometricupdate.com/companies/bioenable-technology-pvt-ltd">BioEnable Technologies</a>.

During the pilot, authorities captured the biometrics of 1,400 registrants, with a success rate of 96 percent, according to the announcement, with 600 more registrations in progress. The team is thus on target to meet the goal of 2,000 successful registrations by the end of August.

BioEnable says the project marks a milestone in Burkina Faso’s journey towards effective digital identity management and inclusive identity services for essential service delivery.

"We are thrilled to have successfully showcased the capabilities of our biometric devices and solutions in implementing MOSIP in Burkina Faso,” says BioEnable CEO Mahesh Ghatge. “This pilot demonstrates our commitment to providing cutting-edge identity solutions that empower governments and citizens alike. We look forward to further collaborations that will enable countries to harness the potential of digital identities for socioeconomic growth."

The pilot showed MOSIP’s efficient management of registration, de-duplication, and authentication to ensure system accuracy, and the platform’s capabilities for providing access to government services like healthcare, education and social welfare through secure digital identity, the company states. It also demonstrated MOSIP’s commitment to data security and privacy, and potential to operate at national scale.

The MOSIP team is also building up its ecosystem of biometric testing laboratories and a <a href="https://www.biometricupdate.com/202307/mosip-ready-for-next-phase-after-building-up-digital-id-ecosystem">framework for device certification</a>. The open source platform’s ecosystem efforts also extend to work on digital wallets.
<h2>MOSIP makes code contribution to OpenWallet Foundation</h2>
MOSIP has also contributed of code to the <a href="https://openwallet.foundation/">OpenWallet Foundation</a> (OWF), its first. The code contribution by MOSIP is intended to spur the development of critical components for the open source software engine of portable and secure digital wallets, according to an announcement from Linux Foundation Europe, which hosts OWF.

MOSIP’s contribution relates to the issuance of verifiable credentials and credential sharing with Bluetooth Low Energy (BLE), based on the OpenID specification. The components are also a part of MOSIP’s <a href="https://www.biometricupdate.com/202302/mosip-prepares-to-launch-inji-digital-wallet-for-all-identity-verification-tool">Inji digital wallet</a>.

OWF has also welcomed Google as a premier member.

"Google joining OWF is a huge validation of our vision to bring together global industry and technology players to collaborate on critical open source projects highly aligned with European priorities, and the MOSIP upcoming contribution shows once again the unique power open source has to build on each others achievements, inevitably accelerating the project's progress towards delivering concrete code-first solutions against those priorities," says Gabriele Columbro, general manager of Linux Foundation Europe.

## Facial recognition & NIST – Fake news or old views?
 - [https://www.biometricupdate.com/202308/facial-recognition-nist-fake-news-or-old-views](https://www.biometricupdate.com/202308/facial-recognition-nist-fake-news-or-old-views)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T17:41:09.910360+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1024" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/23130847/face-photos-diverse-scaled.jpg" width="2048" />
		<em>By Tony Porter, Chief Privacy Officer at <a href="https://corsight.ai/">Corsight AI</a></em>

<em><b>The focus on tests conducted in 2019 skews the debate --  Facial recognition technology algorithms have advanced rapidly since then and public commentators, civil rights groups and lawmakers need to reflect that.</b></em>

The National Institute of Standards and Technology (NIST) <a href="https://www.nist.gov/programs-projects/face-recognition-vendor-test-frvt">Face Recognition Vendor Test</a> (FRVT) program has for many years been the most respected independent and authoritative evaluator of facial recognition algorithms anywhere in the world. The FRVT program examines FR technologies that are submitted by developers voluntarily, for independent testing as to their performance and accuracy. The results are published in the public domain. The first FRVT report on <a href="https://www.biometricupdate.com/201912/nist-report-tackles-issue-of-bias-in-facial-biometrics">demographic effects</a> to be produced by NIST was way back in 2019. This four-year-old report is significant in the modern context for one particular reason, namely that it is often alluded to and misrepresented in policy debates by narrators and in the media, as being indicative of alarming levels of bias within modern facial recognition algorithms being used or being considered for use today.

For clarity, that report does not do that.

That particular 2019 NIST study evaluated 189 software algorithms from 99 developers to determine disparities in performance or ‘bias’ across a diversity of images. The obvious outcome in 2019 was much the same as you would expect today, namely that the quality of performance of any given FRT system depends on the qualities of the algorithm at the heart of the system, the application that uses it and the data it is fed and trained upon.

Back in 2019 the standard of the algorithms in use by the range of systems being tested on that occasion did indeed show a disparity in performance amongst some systems of a factor of 10 to 100 depending upon the algorithm tested.  It is the latter figure which was achieved by the poorest algorithms tested by NIST which is often quoted by critics of FRT today, particularly those seeking to deny the use of this technology to law enforcement agencies. A key message seems to have been lost, conveniently or otherwise, is that different algorithms perform differently.

FR technology has of course <a href="https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software">developed significantly</a> in the four years since the first FRVT report, but the narrative of the naysayers hasn’t always evolved beyond an entrenchment in a selective representation of the 2019 report.

The highly respected FRVT is a regular assessment process and the regular <a href="https://www.biometricupdate.com/202302/facial-recognition-algorithms-hit-new-accuracy-highs-in-latest-nist-test">publication of modern and up-to-date reports</a> relevant to the performance of modern FRT algorithms seems largely ignored by comparison in more contemporary policy debates and media reporting. Were the true facts of the outcomes of current FRVT assessments to achieve at least an equal standing to the out of date representations of the 2019 report, then both policy makers and the public alike could at least have some hope of having factual and up to date information upon which to establish their own views and make better informed decisions.

Modern and better performing FRT systems such as those produced by Corsight AI when tested across 12 million images deliver an accuracy score of 99.88 percent. Any disparity in performance across race, gender and age is so negligible as to be statistically insignificant, so say the independent testers. This level of performance is far in excess of human capability, and with those levels of accuracy, the application of proper risk management controls by human operators can remove such risk altogether.

Across the European Union there have been many reasoned and well-considered arguments put forward particularly by Civil Liberty groups against the use of FRT. Indeed many of these arguments are being advanced now- whilst the EU Trilogue is currently discussing the future of live biometric identification. The unquestionable value in those arguments has challenged law enforcement and has been considered by the courts. Paradoxically, those arguments have probably contributed to the establishment of higher standards of use by organisations and better guidance being produced by regulators and stakeholders alike where FRT is concerned.

The value within FRT to law enforcement and national security agencies is significant and undeniable, the risks are understood, acknowledged and manageable. Indeed, recently Interpol declared that since 2016 there have been 1500 arrests of serious and organised criminals across the EU through the use of FRT. The debate is no longer one of whether or not to deny law enforcement those capabilities which can effectively protect our densely populated, digitally enabled and increasingly dangerous societies from an array of serious harms (EU to note). The debate to be had now is how the regulation of its capabilities should evolve so as to continue to shape and harness its use as a force for good to the benefit of society and to hold such use to account.

That particular debate requires common sense, balance, being grounded in modern fact, and not tainted by old information, misinformation or indeed disinformation as to do otherwise would indeed be akin to being…dystopian!
<h2>About the author</h2>
Tony Porter is <a href="https://www.biometricupdate.com/companies/corsight">Corsight AI'</a>s Chief Privacy Officer and the former UK Surveillance Camera Commissioner. Corsight AI is a leading provider of facial recognition solutions for corporations, law enforcement and other government agencies.

<em>DISCLAIMER: Biometric Update’s Industry Insights are submitted content. The views expressed in this post are that of the author, and don’t necessarily reflect the views of Biometric Update.</em>

## SecureAuth inks new partners to grow reach of biometric passwordless authentication
 - [https://www.biometricupdate.com/202308/secureauth-inks-new-partners-to-grow-reach-of-biometric-passwordless-authentication](https://www.biometricupdate.com/202308/secureauth-inks-new-partners-to-grow-reach-of-biometric-passwordless-authentication)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T16:41:08.007714+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1365" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/03/20155817/passwordless-authentication-scaled.jpg" width="2048" />
		<a href="https://www.biometricupdate.com/companies/secureauth">SecureAuth</a> is continuing to build out its sales channel by announcing partnerships with Idmworks and Opkalla to distribute its behavioral biometrics and passwordless continuous authentication product, Arculix.

The partnerships address evolving challenges in digital identity security, such as digital acceleration, threat environments and business demands including compliance, according to the company announcement.

<a href="https://www.idmworks.com/">Idmworks</a> is an identity and access management (IAM) consultant working with businesses in North America, and is recognized by Gartner as a leading IAM solutions provider. <a href="https://opkalla.com/">Opkalla</a> is a Charlotte, North Carolina-based IT consultancy.

SecureAuth CMO Mandeep Khera calls the companies “market-leading experts in the IAM space.”

“Arculix’s patented and strong passwordless continuous authentication technology will help extend Idmworks’ leadership in the IAM market and help our customers’ real issues around security as well as compliance with Cyber Insurance and other regulations,” says Joe Brown, director of business development of Idmworks.

SecureAuth also recently integrated Arculix with <a href="https://www.biometricupdate.com/202308/secureauth-behavioral-biometrics-passwordless-authentication-built-into-citrix-platform">Citrix Workspace</a>.

## VisionLabs launches upgraded biometric access control terminal, lands deal in UAE
 - [https://www.biometricupdate.com/202308/visionlabs-launches-upgraded-biometric-access-control-terminal-lands-deal-in-uae](https://www.biometricupdate.com/202308/visionlabs-launches-upgraded-biometric-access-control-terminal-lands-deal-in-uae)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T16:41:08.005820+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1325" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/07/10101537/face-biometric-close-up.jpg" width="1312" />
		<a href="https://www.biometricupdate.com/tag/visionlabs">VisionLabs</a>, the Russia-founded facial recognition company with headquarters in the Netherlands, has launched a new version of its biometric access control terminal and says that it has already found a buyer in the United Arab Emirates.

The Luna Ace 2 is a slimmer, more compact version of its facial recognition-based access control device created to cater to government and large enterprise customers. The device features a 7-inch screen and an enhanced system of cameras, and VisionLabs’ “on-the-move” technology allows people to pass through the identity check without even stopping, the company says in a release.

“All those things made us fall in love with smartphones after the cell phone design frenzy of the 2000s,” says Bhushan Kate, the IMEA regional director at VisionLabs. “We designed a beautiful hi-tech device but with enterprise-grade software running on it.”

VisionLabs did not disclose the buyer of its Luna Ace 2 devices – <em>Biometric Update</em> has reached out to the company for more details. However, the company did note that the UAE plans to use the hardware in its infrastructure. The country has been introducing facial recognition in passport control, police, public transport, banking and <a href="https://www.biometricupdate.com/202308/uae-makes-its-single-sign-on-service-the-front-door-for-6k-private-public-services">other public projects</a>.

The company <a href="https://www.businessemirates.ae/news/uae-property-news/rezident-skolkovo-otkryl-ofis-v-oae/">opened</a> its office in Dubai in 2020 and has been <a href="https://www.biometricupdate.com/202101/visionlabs-and-smart-engines-innovatrics-announce-biometric-onboarding-customer-wins">working</a> alongside Armenian computer vision firm <a href="https://www.biometricupdate.com/companies/smart-engines">Smart Engines</a> to provide verification solutions for the Emirates NBD, the largest bank in the UAE.

In July, the company <a href="https://www.biometricupdate.com/202307/visionlabs-introduces-anti-deepfake-tech-clinches-deal-for-govt-biometric-system">introduced</a> its deepfake detection technology with claims that its algorithm’s accuracy rate reaches between 92 and 100 percent, comparable to some of the best in the world.

VisionLabs also said in June it will cooperate with the Russian government on developing technology for the country’s unified biometrics system (UBS). In February, it was <a href="https://www.federalregister.gov/documents/2023/02/27/2023-04099/additions-of-entities-to-the-entity-list-revisions-of-entities-on-the-entity-list">added</a> to the U.S. Department of Commerce Entity List.

## Nigeria’s Borno State to capture biometrics of nearly 7k ex-Boko Haram fighters
 - [https://www.biometricupdate.com/202308/nigerias-borno-state-to-capture-biometrics-of-nearly-7k-ex-boko-haram-fighters](https://www.biometricupdate.com/202308/nigerias-borno-state-to-capture-biometrics-of-nearly-7k-ex-boko-haram-fighters)
 - RSS feed: http://feeds.feedburner.com/biometricupdate
 - date published: 2023-08-23T14:41:03.979012+00:00

<img alt="" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" height="1365" src="https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/06/28184625/digital-identity-scaled.jpg" width="2048" />
		The Commissioner for Information and Internal Security in Nigeria’s North Eastern state of Borno, Usman A. Tar, said over the weekend that a biometric identification process has begun for 6,900 militants of the jihadist terrorist group, Boko Haram, who have dropped their weapons.

The repentant fighters are undergoing reformation at a rehabilitation center in the state under the Disarmament, Demobilization, Deradicalization, Rehabilitation, Reconciliation and Reintegration (DDDRRR) program involving different stakeholders.

A <a href="https://www.rfi.fr/en/international-news/20230411-inside-nigeria-s-centres-for-jihadists-and-their-captives" rel="noopener" target="_blank">report</a> which highlights an investigation by AFP reveals that there have been issues with the identification and screening process for some of the persons living in temporary rehabilitation camps.

In a statement cited by <a href="https://punchng.com/borno-resumes-biometrics-capturing-of-6900-repentant-terrorists/" rel="noopener" target="_blank">Punch</a>, Tar said the identification process is taking place in six batches, and is conducted by a special team of IT  and security experts to ensure confidentiality of the fingerprint biometrics and other data captured.

Boko Haram terrorism started in Borno in 2009. The state remains the most badly hit by the insurgency which has killed an estimated 35,000+ people in Nigeria alone.

Meanwhile, HumAngle <a href="https://humanglemedia.com/uproar-at-holding-pen-for-surrendered-boko-haram-terrorists-triggered-by-poor-planning/" rel="noopener" target="_blank">reports</a> that a protest by some of the repentant fighters on Friday August 18, disrupted the biometric registration process at a capture center.

The outlet mentions that the protesters blocked roads and chanted songs decrying their poor living conditions and slow reintegration into mainstream society.

It also quoted Tar as assuring that the situation, which he said was created by a miscommunication, had been handled, and the biometric capture process would go on as planned.

Nigeria's previous government cited an improved <a href="https://www.biometricupdate.com/202105/nigerian-president-says-digital-id-project-will-help-curb-insecurity">capacity to handle national security threats</a> as one of its motivations for carrying out the country's universal identification project.

