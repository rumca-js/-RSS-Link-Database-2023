[{"source": "http://feeds.feedburner.com/biometricupdate", "title": "Settlement of BIPA suit against Clearview AI could be days away", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1365\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/07111707/black-woman-facial-recognition-scaled.jpg\" width=\"2048\" />\n\t\tA settlement in a U.S. biometric data privacy case involving Clearview AI and other business defendants could be finalized inside a week, according to court documents seen by <em>Biometric Update</em>.\n\nA putative class action alleging that online face photo-scraper <a href=\"https://www.biometricupdate.com/companies/clearview-ai\">Clearview</a> and national retailer Macy's violated the state of Illinois' Biometric Information Privacy Act has idled for a number of weeks.\n\nThe lead plaintiffs and defendants have worked with a mediator to find an acceptable resolution separate from the <a href=\"https://www.troutman.com/a/web/280464/BIOMETRICS-SECTION-1st-BULLET-ClearviewAIPrelimInj.pdf\">contentious</a> case (1:21CV00135) in the U.S. District Court for northeastern Illinois.\n\nBoth sides have submitted to Judge Sharon Johnson Coleman a joint status report indicating that after working through \"numerous\" settlement drafts, they have arrived at a mutually acceptable framework for a settlement, first reported by <a href=\"https://www.mediapost.com/publications/article/388461/clearview-ai-nears-settlement-in-privacy-battle-ov.html\">MediaPost</a>.\n\nLawyers for each side were to have met August 22 with Coleman to answer her questions about the proposed agreement, the next step in getting the judge to approve the settlement and end the case. It's not known on deadline if the meeting took place.\n\nThe case involves at least nine named plaintiffs, six in New York and three in Illinois. The cases were consolidated and heard in Illinois.\n\nClearview is alleged to have broken Illinois law by not getting the plaintiffs' consent before collecting their biometric identifiers. They also, according to court documents, broke biometric privacy laws in Virginia, New York and California.\n\nMacy's is named in the class action because it reportedly used Clearview facial recognition algorithms without getting subjects' consent. The retail chain alleged collected security video images of <a href=\"https://www.cincinnati.com/story/news/2020/08/07/macys-faces-class-action-lawsuit-use-facial-recognition-software-clearview-ai/3315099001/\">6,000 people</a> in its stores for comparison with the billions of face scans collected by Clearview, according to regional newspaper The Cincinnati Enquirer.\n\nSettlement is apparently an attractive option in <a href=\"https://www.biometricupdate.com/202308/bnsf-rail-asks-to-settle-or-retry-its-bipa-damage-award\">another BIPA case</a>, this one involving BNSF Railway.", "link": "https://www.biometricupdate.com/202308/settlement-of-bipa-suit-against-clearview-ai-could-be-days-away", "date_published": "2023-08-23T22:21:17.540267+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Here\u2019s the newest camera hack fraudsters are using to beat facial recognition", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1365\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/02/22111201/face-biometric-enrollment-scaled.jpg\" width=\"2048\" />\n\t\t<em>By Stuart Wells, Chief Technology Officer at </em><a href=\"https://www.jumio.com\"><em>Jumio</em></a>\n\nAs organizations have tried to stay ahead of cybercriminals, faces and other biometrics have become the passwords for so many everyday functions. From unlocking a phone, to accessing a bank account, to setting up a doctor\u2019s appointment, important tasks are completed by verifying that the correct face is the one behind (or in front of) the camera.\n\nHowever, like with traditional passwords, fraudsters have gotten creative about getting around facial recognition security. By now, most everyone understands deepfakes and the threats associated with them. Since, by definition, a deepfake is an altered or fabricated video sequence, cybercriminals depend on a technique known as \u201ccamera injection\u201d to beat facial recognition systems.\n\nSome experts have <a href=\"https://www.europol.europa.eu/cms/sites/default/files/documents/Europol_Innovation_Lab_Facing_Reality_Law_Enforcement_And_The_Challenge_Of_Deepfakes.pdf\">predicted</a> that as much as 90 percent of content on the web could be synthetically generated by 2026, making it increasingly difficult for organizations to discern which users are who they claim to be. Here is a rundown on how fraudsters are pulling off camera injection attacks, what makes it so dangerous and how organizations can protect themselves.\n<h2>How do camera injection attacks work?</h2>\nAs passwords have evolved beyond numerical and alphabetical characters, hackers have been pushed to adapt beyond the likes of brute force attacks and credential stuffing. Beating facial recognition software requires a far greater level of sophistication, which has led to the invention of tactics designed to trick biometric and liveness detection tools.\n\nFraudsters introduce deepfake videos into the system using a camera <a href=\"https://www.biometricupdate.com/tag/injection-attacks\">injection attack</a>. Camera injection occurs when a fraudster bypasses the charged-coupled device (CCD) of a camera to inject pre-recorded content, a real-time face swap video stream or completely fabricated (deepfake) content. This pre-recorded content could be an unaltered video of a real person that a bad actor is attempting to defraud. The pre-recorded or real-time generated video could be a clip where the face is altered in some way, or of a completely synthetic face that does not exist.\n\nThe bypass of a live feed that a real camera\u2019s CCD would normally capture is accomplished through a couple of methods. One is by hacking the device driver of a real camera and injecting the video stream into a lower level of the device driver. The more common means of camera injection is to have a virtual camera device driver that simply feeds a pre-recorded or real-time generated video stream to the system, presenting it as a real camera feed.\n\nSince a video is a series of still images, a fraudster will sometimes feed the same image into every frame of a video stream. The result is a video stream where there is no motion. A more sophisticated technique, but also more time-intensive for the fraudsters, is altering or fabricating a video sequence where motion is present. The most sophisticated technique is where a deepfake can be manipulated in real time to perform actions asked for by the integrated data viewer system.\n<h2>What is the threat?</h2>\nOnce an attacker has successfully passed through this stage of verification, they will have access to an account that is not theirs, leaving them free to wreak havoc under a synthetic or stolen identity. From there, malicious actors can register for phony accounts, complete fraudulent transactions and more.\n\nThe primary concern with the camera injection technique is that, if done successfully, organizations will not realize they have been beaten. If the facial recognition technology in place believes it has properly verified a user\u2019s identity when it has actually been fooled by camera injection, fraudsters can essentially sneak in undetected.\n\nOnly when an account conducts some kind of suspicious behavior, like an unusual bank transaction, would an organization determine that they may have fallen victim to this kind of attack. In many cases, by the time an organization detects the threat, the damage to a user\u2019s account has already been done.\n<h2>Can camera injection attacks be prevented?</h2>\nWhile fraudsters\u2019 tactics continue to evolve, so do the mechanisms designed to keep them out. Robust identity verification with sophisticated liveness detection tools can protect organizations from fraudsters employing the camera injection technique.\n\nTo defend against this type of tactic, organizations can establish controls to detect when a camera device driver has been compromised, when a virtual camera is being used and/or when forensic evaluation of a video stream reveals manipulation or fabrication.\n\nComparing natural motion to the motions in the captured video can help reveal manipulation. Elements like eye motion, expression changes or regular blinking patterns occur naturally. If no such motion is detected, there is a high chance that a single image is being replayed to create a video sequence.\n\nThe capture process can also inject artifacts that should alter the captured images in ways that are detectable. Some of these could be changing the camera parameters (like ISO, aperture, frame rate, resolution, etc.) and observing whether the expected changes occur in the capture. Another could be changing the color or illumination intensity of the device's screen and looking for a corresponding reflection from the face being captured.\n\nBy relying on the accelerometer within the device used to take a verification selfie, and comparing it to the changes in the objects (e.g., face) captured during the video, organizations can determine whether a camera has been compromised by a potential hacker. The individual frames of the video can be forensically analyzed for signs of tampering, such as double compressed parts of the image, or for artifacts indicating a computer-generated (deepfake) image.\n<h2>Living without fear of fraudsters</h2>\nFacial recognition tools are meant to supply an added level of security for organizations, and the emergence of the camera injection technique has been a legitimate threat to that extra layer of protection.\n\nA recent Jumio survey revealed that 52 percent of respondents <a href=\"https://www.jumio.com/2023-identity-study/\">believe</a> they can accurately detect a deepfake video, but the reality is that synthetic content is growing more sophisticated and harder to decipher. In a recent <a href=\"https://www.channelnewsasia.com/business/deepfake-scam-china-fans-worries-over-ai-driven-fraud-3506361\">incident</a> in China, an AI-powered video impersonator assumed the identity of the victim\u2019s friend and scammed them out of more than $600,000.\n\nAs prevalent as the threat of synthetic content may be, sophisticated liveness detection during the identity verification process enables businesses to stay ahead of hackers attempting to use techniques like camera injection. With these resources at their disposal, organizations can feel confident that malicious actors are being kept at bay while ensuring legitimate business users can still gain entry to their accounts.\n<h2>About the author</h2>\n<strong>\u00a0</strong>As Chief Technology Officer at <a href=\"https://www.biometricupdate.com/companies/jumio\">Jumio</a>, Stuart is responsible for all aspects of Jumio\u2019s innovation, machine learning and engineering. An industry veteran with more than 30 years of tech experience, Stuart previously was the chief product and technology officer at FICO and held executive positions at Avaya and Sun Microsystems.\n\n<em>DISCLAIMER: Biometric Update\u2019s Industry Insights are submitted content. The views expressed in this post are that of the author, and don\u2019t necessarily reflect the views of Biometric Update.</em>", "link": "https://www.biometricupdate.com/202308/heres-the-newest-camera-hack-fraudsters-are-using-to-beat-facial-recognition", "date_published": "2023-08-23T22:21:17.538379+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Self-sovereign identity\u2019s promise is big but so are its challenges", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1365\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/04/28130003/tablet-digital-identity-open-banking-scaled.jpg\" width=\"2048\" />\n\t\tToday\u2019s consumers do not have much say in deciding the destiny of their data. They might not be able to define rules on data privacy, nor to decide how their data should be used by Google, Amazon and others.\n\nSelf-sovereign identity (SSI) could solve that issue by giving control over biometric data to consumers. A new paper <a href=\"https://dl.acm.org/doi/10.1145/3616400\">published </a>by the Association for Computing Machinery (ACM) illustrates SSI\u2019s place among other data-management concepts and its challenges.\n\nData sovereignty can be understood two ways -- people\u2019s right to control their data and as data residency. In the first case, the authors propose that data be governed by the CARE principles for indigenous data governance and the FAIR principles.\n\nCARE (collective benefit, authority to control, responsibility and ethics) is the first attempt to outline collective rights as part of the movement to open data in the context of the United Nations Declaration on the Rights of Indigenous Peoples. FAIR (findable, accessible, interoperable and reusable) principles were developed in the Netherlands in 2015 and have since become a way of sharing data that maximizes the use and re-use of data.\n\nData residency, on the other hand, is when a business or government specifies the geographical location of its data. The European Union\u2019s General Data Protection Regulation (GDPR) includes data residence.\n\nAnother connected term is digital sovereignty, which is getting increasing attention in the context of control over digital assets. Digital sovereignty has been used to convey the idea that governments should reassert their authority over the internet and protect their citizens and businesses with regulations.\n\n<a href=\"https://www.biometricupdate.com/tag/self-sovereign-identity\">Self-sovereign identity</a> is a relatively new decentralized model that has the potential to solve the problems of digital identification and authentication and to give individuals full control of their digital identity, according to the ACM researchers.\n\nSelf-sovereign identities are supposed to provide a digital identity, prevent theft and fraud, assure privacy and help get rid of passwords. But it faces challenges.\n\nAmong them are challenges in decentralized identifiers, which are often related to the distribution of public keys, the security of users\u2019 personal data and identities, the scalability and reliability of decentralized identifiers, which are commonly based on blockchains and on ensuring users can keep their identities private.\n\nBut there are issues beyond technical ones that SSIs have to solve, including standardization. The market is fragmented with legal and regulatory uncertainty. The research also lists relevant frameworks, policy and regulations connected to SSI.\n\nA meta-analysis of research in the self-sovereign identity field shows that most papers focus either on the proof of concept or on the prototype implementation of the concept. Another portion of the research focuses on domains or industries where SSI solutions can be applied. This includes financial banking, education, certification, healthcare, transport, e-government and IoT.\n\nThe paper was written by Kheng Leong Tan, Chi-Hung Chi and Kwok-Yan Lam from the Nanyang Technological University in Singapore.", "link": "https://www.biometricupdate.com/202308/self-sovereign-identitys-promise-is-big-but-so-are-its-challenges", "date_published": "2023-08-23T20:21:14.605910+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "GEDmatch loophole allows the police to access user DNA without their consent", "description": "<img alt=\"DNA\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1333\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2021/07/20165204/dna.jpg\" width=\"2000\" />\n\t\tOn August 14th, DNA biometrics testing identified a body that was found on pilings in a Washington river a year ago, according to a release from the Cowlitz County Sheriff's Office. It was too decomposed to conduct facial recognition or take fingerprints, the <a href=\"https://www.tri-cityherald.com/news/state/washington/article278489234.html\">Tri-City Herald</a> reports.\n\nInvestigators partnered with <a href=\"https://othram.com/\">Othram</a>, a forensic genetic genealogy lab in Texas, which was able to identify the brother of the unidentified body. The brother confirmed the deceased man was 55-year old Bryan M. Heinrich Sr. based on a tattoo. While there was no foul play in this instance, the case raises questions about privacy concerns with the use of DNA databases in criminal investigations.\n\nBy using a privacy loophole in GEDmatch's services, Cece More, an actress and director-turned-genetic genealogist, worked with law enforcement agencies to use commercial DNA databases to help identify unknown human remains or perpetrators who left DNA at a crime scene, according to <a href=\"https://theintercept.com/2023/08/18/gedmatch-dna-police-forensic-genetic-genealogy/\">The Intercept</a>.\n\nPolice and the genealogists working with them can access the loophole by manipulating search fields within a DNA comparison tool to show profiles of individuals who explicitly opted out of sharing their information with police.\n\nRecords of communications reveal that Moore, along with two other forensic genealogists discuss how to trigger the loophole, mentioning to hide that her organization made an identification using an opted-out profile.\n\nBack in 2018 Joseph James DeAngelo, the Golden State Killer, was arrested after a broad, invasive search conducted without a warrant and in such a manner that it appeared to violate the privacy policy of at least one DNA company, according to the <a href=\"https://www.latimes.com/california/story/2020-12-08/man-in-the-window\">LA times</a>.\n\nProsecutors claim to have used family tree searchers to find relatives of the killer to initially identify DeAngelo. Afterwards, a detective confirmed investigators uploaded semen from a rape kit to develop a DNA profile that was then uploaded to GEDmatch, an open-source platform.\n\nProsecutors did not share that the genetic material was first sent to FamilyTreeDNA, which allowed law enforcement to create a fake account and search for matching customers. After finding only distant leads, they uploaded the profile to MyHeritage where they identified a close relative who helped break the case.\n\nAfter The Intercept initially shared its reporting on <a href=\"https://www.biometricupdate.com/202106/curbs-on-biometric-dna-searches-by-cops-not-a-trend-yet\">GEDmatch</a>, Margaret Press, founder of the DNA Doe Project, released a statement.\n\n\u201cIn hindsight, it\u2019s clear we failed to consider the critically important need for the public to be able to trust that their DNA data will only be shared and used with their permission and under the restrictions they choose,\" she says.\n\n\"We should have reported these bugs to GEDmatch and stopped using the affected reports until the bugs were fixed,\" continues Press. \"Instead, on that first day when we found that all of the profiles were set to opt-out, I discouraged our team from reporting them at all. I now know I was wrong and I regret my words and actions.\"", "link": "https://www.biometricupdate.com/202308/gedmatch-loophole-allows-the-police-to-access-user-dna-without-their-consent", "date_published": "2023-08-23T20:21:14.596604+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Worldcoin biometrics collection faces more scrutiny in Kenya, skepticism in India", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"761\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/04/29155417/worldcoin-orb-indonesia.png\" width=\"1422\" />\n\t\t<a href=\"https://www.biometricupdate.com/companies/worldcoin\">Worldcoin</a>, the project that wants to scan your iris biometrics in exchange for some of its cryptocurrency, continues to attract regulators in Kenya and skepticism in countries like India, which has just come out with its new data privacy law.\n\nAfter Kenyan data protection authorities ordered Worldcoin to <a href=\"https://www.biometricupdate.com/202308/data-protection-authorities-in-kenya-argentina-investigating-worldcoin\">suspend enrolments</a> earlier this month and <a href=\"https://www.biometricupdate.com/202308/worldcoin-biometric-enrollment-frenzy-sparks-raid-concerns\">police raided</a> its offices in Nairobi, the East African country has formed a parliamentary committee to investigate the company\u2019s operations.\n\nThe 15-member team, led by parliament member Gabriel Tongoyo, will have 42 days to submit its report. Other state agencies, including those covering security, protection and financial services, have started their own inquiries to establish the legality of Worldcoin\u2019s operations, The Star <a href=\"https://www.the-star.co.ke/news/realtime/2023-08-21-parliament-forms-committee-to-investigate-worldcoin-project/\">reports</a>.\n\nThe main issue troubling Kenyan regulators is Worldcoin\u2019s plan to register citizens through the collection of iris data. Kenya\u2019s Office of the Data Protection Commissioner (ODPC), which has been looking into the company since 2022, argues that the company is likely to violate the local Data Protection Act by handling user data, including iris and face biometrics.\n\nThe government is also facing pressure from rights organizations. Amnesty International and the Open Institute have expressed concern over the lack of information on security measures and the data collected.\n\n\u201cPreliminary statements from State agencies suggest a significant data breach in Kenya. We urgently call for thorough and independent investigations by the Data Commissioner,\u201d the organizations say in a statement <a href=\"https://www.the-star.co.ke/news/realtime/2023-08-11-lobbyists-to-state-come-clear-on-protection-of-worldcoin-data/\">published </a>by The Star.\n\nThe NGOs also called for clarifications on whether Worldcoin submitted a Data Protection Impact Assessment and whether the company obtained proper consent from its users. One of the criticisms the project has faced is that many people are lured by the promise of easy money in exchange for a quick eyeball scan and are not aware of <a href=\"https://www.biometricupdate.com/202308/worldcoin-biometric-enrollment-frenzy-sparks-raid-concerns\">potential trade-offs</a> such as limited legal action against the company.\n\nAlex Blania, a co-founder of Worldcoin, has defended the project aimed at providing each person in the world with digital IDs and financial services by emphasizing its commitment to privacy and security. But regulators in countries such as the UK, France and Germany \u2013 which has launched its own investigation \u2013 have been <a href=\"https://www.biometricupdate.com/202307/multiple-regulators-turn-gaze-to-worldcoins-iris-collection\">turning their gaze</a> toward the crypto project. Its latest criticism comes from India.\n<h2>India's new data law may not be enough to protect users from Worldcoin: Rights lawyer</h2>\nThe Indian Parliament has passed its new <a href=\"https://www.meity.gov.in/writereaddata/files/Digital%20Personal%20Data%20Protection%20Act%202023.pdf\">Digital Personal Data Protection Act</a> with implementation expected within 10 months. The Act will affect Worldcoin\u2019s plans to collect data from users in India but they may not be enough to guarantee accountability, Prasanna S., a lawyer at digital rights organization Article 21 Trust, <a href=\"https://www.medianama.com/2023/08/223-interview-advoc-prasanna-legality-worldcoins-operations-in-india/\">explains</a> in an interview with tech outlet Medianama.\n\n\u201cWe know the safeguards are not anywhere near the ideal that we want,\u201d says Prasanna.\n\nIn India, it is legal to create a database of biometric data such as Worldcoin so long as it is optional and the consent is free and informed. Unless it can be established that significant harm was caused by the data collection activity, it\u2019s going to be very difficult to move in a policy direction that prevents private companies from collecting biometric data, he notes.\n\nThis may present a problem: Unlike state projects such as India\u2019s ID number Aadhaar which is closely followed by the public, with private projects that collect biometric data the regulatory regime is \u201cvery superficial.\u201d\n\n\u201cIt's not just a privacy-related concern,\u201d says Prasanna. \u201cWhen the work of private companies impacts fundamental rights or human rights users or citizens at large, what is the accountability?\u201d\n\nAn <a href=\"https://www.medianama.com/2023/08/223-is-worldcoin-collection-of-biometric-data-legal-in-india/\">analysis</a> by Medianama states that Worldcoin\u2019s collection of user data in India appears to be legal.\n\nIndia\u2019s current data protection regime, dating from 2000, classifies bank details and biometric information as sensitive personal information. Companies need to disclose the purpose for which it has been collected while allowing people the option to delete or correct the data being collected.\n\nWorldcoin defines a clear purpose for which it is collecting data \u2013 to prevent fraudulent users from signing up more than once \u2013 and offers a consent form explaining that the company will retain\u00a0 unique iris code based on the image of the users\u2019 irises obtained through their imaging device, the Orb.", "link": "https://www.biometricupdate.com/202308/worldcoin-biometrics-collection-faces-more-scrutiny-in-kenya-skepticism-in-india", "date_published": "2023-08-23T20:21:14.595014+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Walmart Spark delivery platform picks Persona selfie biometrics for driver verification", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1536\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/23153113/shutterstock_2188692801-scaled.jpg\" width=\"2048\" />\n\t\tWalmart delivery app Spark is implementing selfie biometrics checks from <a href=\"https://www.biometricupdate.com/companies/persona\">Persona</a> for drivers to cut down on incidents of individuals using identity fraud to corner the market for delivery jobs.\n\nThe delivery platform has scaled quickly, with three times more drivers than a year ago, <a href=\"https://www.businessinsider.com/walmart-spark-delivery-app-multiple-accounts-names-verify-identity-2023-8\">Business Insider</a> reports. Several drivers who spoke to Insider say that as that has happened, they have been given less orders to complete through the crowdsourced delivery app. Meanwhile, Walmart employees claim to have seen other drivers using multiple identities and multiple phones to get more work by gaming the system.\n\nIn response, Walmart is instituting identity verification through ID document photos and selfie biometrics. The <a href=\"https://drive4spark.walmart.com/spark-driver-privacy-statement\">Spark driver app privacy statement</a> reveals that the technology is provided by Persona.\n\nPreviously, some stores had begun checking drivers\u2019 physical IDs before releasing orders, but others said they were not allowed to do so. A Walmart spokesperson told Insider that the company takes reports of fraud seriously and that fraudulent accounts are deactivated whenever they are found through active monitoring.\n\nThe change seems to include not just onboarding but biometric authentication, with Insider reporting that verifications include periodic selfie requests. How frequent authentication will be required remains unclear, with reports of selfies requested for each delivery at one store early last week, and much less frequently by the end of the week.\n\nDelivery platforms including <a href=\"https://www.biometricupdate.com/201904/amazon-secures-delivery-contractor-accounts-with-biometric-facial-verification\">Amazon</a>, <a href=\"https://www.biometricupdate.com/202307/checkout-com-launches-selfie-biometrics-solution-for-seamless-customer-onboarding\">Uber Eats</a> and <a href=\"https://www.biometricupdate.com/202109/persona-raises-150m-renews-development-efforts-in-digital-id-solutions-and-infrastructures\">DoorDash</a> already use selfie biometrics and ID checks.\n\nPersona has won several major contracts for biometric identity verification of late, the aforementioned DoorDash among them, along with online game <a href=\"https://www.biometricupdate.com/202306/persona-wins-major-gaming-client-as-age-verification-grows-up\">Roblox</a>.", "link": "https://www.biometricupdate.com/202308/walmart-spark-delivery-platform-picks-persona-selfie-biometrics-for-driver-verification", "date_published": "2023-08-23T20:21:14.593293+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Gov\u2019ts debate AI rules but the results don\u2019t command", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1152\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/02/14134710/facial-recogntiion-street-crowd-scaled.jpg\" width=\"2048\" />\n\t\tLeaders of Australia, Ireland, Israel, the United States and the Group of Seven (G7) finance ministers are seeking input on AI regulations, according to a <a href=\"https://www.reuters.com/technology/governments-race-regulate-ai-tools-2023-08-22/\">handy guide</a> published by Reuters. The European Union, United Kingdom and United Nations are planning regulations while China has implemented temporary regulations.\n\nAnd Italy, Japan, Spain and France are investigating possible data and privacy breaches involving AI.\n<h2>AI measures an \u2018urgent issue,\u2019 says US policy advisor</h2>\nThe White House is considering many measures connected to regulating AI, but their timeline is uncertain, <a href=\"https://www.registercitizen.com/business/article/white-house-science-adviser-calls-for-more-18306270.php\">according to</a> an Associated Press interview with Washington technology advisor Arati Prabhakar this week.\n\n\u201cThe president has been clear that this is an urgent issue,\u201d he reportedly told the AP. Prabhakar directs the White House Office of Science and Technology Policy.\n\nHis office is helping to shape the government's approach to AI, relying on cooperation with industry leaders. In July, seven companies, including Meta, Google, Microsoft and ChatGPT-maker <a href=\"https://www.biometricupdate.com/202307/chatgpt-facial-recognition-potential-makes-openai-nervous\">OpenAI</a> agreed to meet voluntary AI safety standards set by the White House.\n\nOne of the issues being examined is the black-box development of most machine-learning code, said Prabhakar. But there are enough other AI concerns that some people worry that algorithms could become a djinn sprung loose from the bottle, with unexpected and possibly dangerous consequences.\n\nFor example, he said, \u201cthere\u2019s now a fairly substantial, distressing history of facial recognition systems being used inappropriately and leading to <a href=\"https://www.biometricupdate.com/202308/black-woman-matched-by-facial-recognition-alleges-police-misconduct-in-lawsuit\">wrongful arrests</a> of Black people.\"\n<h2>Australian rights commission: We need our own AI Act</h2>\nCommissioners are <a href=\"https://humanrights.gov.au/about/news/australia-needs-ai-regulation\">warning</a> that the country urgently needs an AI Act similar to the one being meted out in the E.U.\n\nThey also are asking for a dedicated AI safety commissioner who would not have an enforcement role but who instead would assist regulators on the topic, InnovationAus.com <a href=\"https://www.innovationaus.com/ai-act-needed-to-protect-human-rights-hrc/?utm_medium=email&amp;utm_campaign=Newsletter1149-18August2023&amp;utm_content=Newsletter1149-18August2023+CID_fe33ff4661612d617ef308757a918011&amp;utm_source=Emailmarketingsoftware&amp;utm_term=AIActneededtoprotecthumanrightsHRC&amp;utm_term=AIActneededtoprotecthumanrightsHRC\">reports</a>.\n\n\u201cIf Australia is to reap the benefits of AI, it must ensure the technology is developed and used ethically,\u201d says Rights Commissioner Lorraine Finlay.\n\nThe organization says it has submitted 47 recommendations to the Industry Department, noting that many issues complicating the use of AI could be resolved with improvements to legal frameworks including privacy laws.\n\nIn 2021, the commission published a report with similar recommendations. The organization had called on the government to halt use of facial recognition and other AI algorithms for important decisions until protections are in place. Its findings were largely ignored by the previous government, the report notes.\n\nAustralia is seeking input on regulations but that call has divided stakeholders. Some in industry want technology-neutral regulations while others are advocating more government intervention, according to the report.\n<h2>Women AI ethics researchers are leading the call for regulation</h2>\nAs the debates on AI have grown during the past year, many creators of these algorithms have issued alarms about AI's effects on society .\n\nYet female AI-ethics researchers have been warning for years about the societal effects of AI systems and their problematic interactions with people of color and other marginalized communities.\n\nIn an <a href=\"https://www.rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/\">interview</a> with culture and news publisher Rolling Stone, AI thought leaders such as <a href=\"https://www.biometricupdate.com/201907/buolamwini-gebru-and-raji-win-ai-innovation-award-for-research-into-biometric-bias\">Timnit Gebru</a>, Safiya Noble, Rumman Chowdhury, Seeta Pe\u00f1a Gangadharan and Joy Buolamwini discussed how their findings on AI bias and other problems have often been dismissed.\n\n<a href=\"https://www.biometricupdate.com/201907/buolamwini-gebru-and-raji-win-ai-innovation-award-for-research-into-biometric-bias\">Buolamwini\u2019</a>s Algorithmic Justice League has been looking into reported harms caused by the Transportation Security Administration's expanded use of face biometrics to 25 airports across the U.S. The computer scientist and digital activist with the MIT Media Lab was invited this summer to speak to President Joe Biden at a closed-door roundtable on AI.\n\nEthically training AI is crucial, she says, while treating the algorithms like ordinary code could pose dire consequences.", "link": "https://www.biometricupdate.com/202308/govts-debate-ai-rules-but-the-results-dont-command", "date_published": "2023-08-23T20:21:14.591448+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "MOSIP implementation pilot with BioEnable biometrics nears successful completion", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1537\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/06/20161235/mosip_compliant-scaled.jpg\" width=\"2048\" />\n\t\tA pilot implementation of the <a href=\"https://www.biometricupdate.com/companies/mosip-modular-open-source-identification-platform\">MOSIP</a> digital identity platform is nearing completion in Burkina Faso using biometric devices and software from <a href=\"https://www.biometricupdate.com/companies/bioenable-technology-pvt-ltd\">BioEnable Technologies</a>.\n\nDuring the pilot, authorities captured the biometrics of 1,400 registrants, with a success rate of 96 percent, according to the announcement, with 600 more registrations in progress. The team is thus on target to meet the goal of 2,000 successful registrations by the end of August.\n\nBioEnable says the project marks a milestone in Burkina Faso\u2019s journey towards effective digital identity management and inclusive identity services for essential service delivery.\n\n\"We are thrilled to have successfully showcased the capabilities of our biometric devices and solutions in implementing MOSIP in Burkina Faso,\u201d says BioEnable CEO Mahesh Ghatge. \u201cThis pilot demonstrates our commitment to providing cutting-edge identity solutions that empower governments and citizens alike. We look forward to further collaborations that will enable countries to harness the potential of digital identities for socioeconomic growth.\"\n\nThe pilot showed MOSIP\u2019s efficient management of registration, de-duplication, and authentication to ensure system accuracy, and the platform\u2019s capabilities for providing access to government services like healthcare, education and social welfare through secure digital identity, the company states. It also demonstrated MOSIP\u2019s commitment to data security and privacy, and potential to operate at national scale.\n\nThe MOSIP team is also building up its ecosystem of biometric testing laboratories and a <a href=\"https://www.biometricupdate.com/202307/mosip-ready-for-next-phase-after-building-up-digital-id-ecosystem\">framework for device certification</a>. The open source platform\u2019s ecosystem efforts also extend to work on digital wallets.\n<h2>MOSIP makes code contribution to OpenWallet Foundation</h2>\nMOSIP has also contributed of code to the <a href=\"https://openwallet.foundation/\">OpenWallet Foundation</a> (OWF), its first. The code contribution by MOSIP is intended to spur the development of critical components for the open source software engine of portable and secure digital wallets, according to an announcement from Linux Foundation Europe, which hosts OWF.\n\nMOSIP\u2019s contribution relates to the issuance of verifiable credentials and credential sharing with Bluetooth Low Energy (BLE), based on the OpenID specification. The components are also a part of MOSIP\u2019s <a href=\"https://www.biometricupdate.com/202302/mosip-prepares-to-launch-inji-digital-wallet-for-all-identity-verification-tool\">Inji digital wallet</a>.\n\nOWF has also welcomed Google as a premier member.\n\n\"Google joining OWF is a huge validation of our vision to bring together global industry and technology players to collaborate on critical open source projects highly aligned with European priorities, and the MOSIP upcoming contribution shows once again the unique power open source has to build on each others achievements, inevitably accelerating the project's progress towards delivering concrete code-first solutions against those priorities,\" says Gabriele Columbro, general manager of Linux Foundation Europe.", "link": "https://www.biometricupdate.com/202308/mosip-implementation-pilot-with-bioenable-biometrics-nears-successful-completion", "date_published": "2023-08-23T18:41:11.900019+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Facial recognition & NIST \u2013 Fake news or old views?", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1024\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/08/23130847/face-photos-diverse-scaled.jpg\" width=\"2048\" />\n\t\t<em>By Tony Porter, Chief Privacy Officer at <a href=\"https://corsight.ai/\">Corsight AI</a></em>\n\n<em><b>The focus on tests conducted in 2019 skews the debate --\u00a0 Facial recognition technology algorithms have advanced rapidly since then and public commentators, civil rights groups and lawmakers need to reflect that.</b></em>\n\nThe National Institute of Standards and Technology (NIST)\u00a0<a href=\"https://www.nist.gov/programs-projects/face-recognition-vendor-test-frvt\">Face Recognition Vendor Test</a>\u00a0(FRVT) program has for many years been the most respected independent and authoritative evaluator of facial recognition algorithms anywhere in the world. The FRVT program examines FR technologies that are submitted by developers voluntarily, for independent testing as to their performance and accuracy. The results are published in the public domain. The first FRVT report on <a href=\"https://www.biometricupdate.com/201912/nist-report-tackles-issue-of-bias-in-facial-biometrics\">demographic effects</a> to be produced by NIST was way back in 2019. This four-year-old report is significant in the modern context for one particular reason, namely that it is often alluded to and misrepresented in policy debates by narrators and in the media, as being indicative of alarming levels of bias within modern facial recognition algorithms being used or being considered for use today.\n\nFor clarity, that report does not do that.\n\nThat particular 2019 NIST study evaluated 189 software algorithms from 99 developers to determine disparities in performance or \u2018bias\u2019 across a diversity of images. The obvious outcome in 2019 was much the same as you would expect today, namely that the quality of performance of any given FRT system depends on the qualities of the algorithm at the heart of the system, the application that uses it and the data it is fed and trained upon.\n\nBack in 2019 the standard of the algorithms in use by the range of systems being tested on that occasion did indeed show a disparity in performance amongst some systems of a factor of 10 to 100 depending upon the algorithm tested.\u00a0\u00a0It is the latter figure which was achieved by the poorest algorithms tested by NIST which is often quoted by critics of FRT today, particularly those seeking to deny the use of this technology to law enforcement agencies. A key message seems to have been lost, conveniently or otherwise, is that different algorithms perform differently.\n\nFR technology has of course <a href=\"https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software\">developed significantly</a> in the four years since the first FRVT report, but the narrative of the naysayers hasn\u2019t always evolved beyond an entrenchment in a selective representation of the 2019 report.\n\nThe highly respected FRVT is a regular assessment process and the regular <a href=\"https://www.biometricupdate.com/202302/facial-recognition-algorithms-hit-new-accuracy-highs-in-latest-nist-test\">publication of modern and up-to-date reports</a> relevant to the performance of modern FRT algorithms seems largely ignored by comparison in more contemporary policy debates and media reporting. Were the true facts of the outcomes of current FRVT assessments to achieve at least an equal standing to the out of date representations of the 2019 report, then both policy makers and the public alike could at least have some hope of having factual and up to date information upon which to establish their own views and make better informed decisions.\n\nModern and better performing FRT systems such as those produced by Corsight AI when tested across 12 million images deliver an accuracy score of 99.88 percent. Any disparity in performance across race, gender and age is so negligible as to be statistically insignificant, so say the independent testers. This level of performance is far in excess of human capability, and with those levels of accuracy, the application of proper risk management controls by human operators can remove such risk altogether.\n\nAcross the European Union there have been many reasoned and well-considered arguments put forward particularly by Civil Liberty groups against the use of FRT. Indeed many of these arguments are being advanced now- whilst the EU Trilogue is currently discussing the future of live biometric identification. The unquestionable value in those arguments has challenged law enforcement and has been considered by the courts. Paradoxically, those arguments have probably contributed to the establishment of higher standards of use by organisations and better guidance being produced by regulators and stakeholders alike where FRT is concerned.\n\nThe value within FRT to law enforcement and national security agencies is significant and undeniable, the risks are understood, acknowledged and manageable. Indeed, recently Interpol declared that since 2016 there have been 1500 arrests of serious and organised criminals across the EU through the use of FRT. The debate is no longer one of whether or not to deny law enforcement those capabilities which can effectively protect our densely populated, digitally enabled and increasingly dangerous societies from an array of serious harms (EU to note). The debate to be had now is how the regulation of its capabilities should evolve so as to continue to shape and harness its use as a force for good to the benefit of society and to hold such use to account.\n\nThat particular debate requires common sense, balance, being grounded in modern fact, and not tainted by old information, misinformation or indeed disinformation as to do otherwise would indeed be akin to being\u2026dystopian!\n<h2>About the author</h2>\nTony Porter is <a href=\"https://www.biometricupdate.com/companies/corsight\">Corsight AI'</a>s Chief Privacy Officer and the former UK Surveillance Camera Commissioner. Corsight AI is a leading provider of facial recognition solutions for corporations, law enforcement and other government agencies.\n\n<em>DISCLAIMER: Biometric Update\u2019s Industry Insights are submitted content. The views expressed in this post are that of the author, and don\u2019t necessarily reflect the views of Biometric Update.</em>", "link": "https://www.biometricupdate.com/202308/facial-recognition-nist-fake-news-or-old-views", "date_published": "2023-08-23T17:41:09.910360+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "SecureAuth inks new partners to grow reach of biometric passwordless authentication", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1365\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/03/20155817/passwordless-authentication-scaled.jpg\" width=\"2048\" />\n\t\t<a href=\"https://www.biometricupdate.com/companies/secureauth\">SecureAuth</a> is continuing to build out its sales channel by announcing partnerships with Idmworks and Opkalla to distribute its behavioral biometrics and passwordless continuous authentication product, Arculix.\n\nThe partnerships address evolving challenges in digital identity security, such as digital acceleration, threat environments and business demands including compliance, according to the company announcement.\n\n<a href=\"https://www.idmworks.com/\">Idmworks</a> is an identity and access management (IAM) consultant working with businesses in North America, and is recognized by Gartner as a leading IAM solutions provider. <a href=\"https://opkalla.com/\">Opkalla</a> is a Charlotte, North Carolina-based IT consultancy.\n\nSecureAuth CMO Mandeep Khera calls the companies \u201cmarket-leading experts in the IAM space.\u201d\n\n\u201cArculix\u2019s patented and strong passwordless continuous authentication technology will help extend Idmworks\u2019 leadership in the IAM market and help our customers\u2019 real issues around security as well as compliance with Cyber Insurance and other regulations,\u201d says Joe Brown, director of business development of Idmworks.\n\nSecureAuth also recently integrated Arculix with <a href=\"https://www.biometricupdate.com/202308/secureauth-behavioral-biometrics-passwordless-authentication-built-into-citrix-platform\">Citrix Workspace</a>.", "link": "https://www.biometricupdate.com/202308/secureauth-inks-new-partners-to-grow-reach-of-biometric-passwordless-authentication", "date_published": "2023-08-23T16:41:08.007714+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "VisionLabs launches upgraded biometric access control terminal, lands deal in UAE", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1325\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2023/07/10101537/face-biometric-close-up.jpg\" width=\"1312\" />\n\t\t<a href=\"https://www.biometricupdate.com/tag/visionlabs\">VisionLabs</a>, the Russia-founded facial recognition company with headquarters in the Netherlands, has launched a new version of its biometric access control terminal and says that it has already found a buyer in the United Arab Emirates.\n\nThe Luna Ace 2 is a slimmer, more compact version of its facial recognition-based access control device created to cater to government and large enterprise customers. The device features a 7-inch screen and an enhanced system of cameras, and VisionLabs\u2019 \u201con-the-move\u201d technology allows people to pass through the identity check without even stopping, the company says in a release.\n\n\u201cAll those things made us fall in love with smartphones after the cell phone design frenzy of the 2000s,\u201d says Bhushan Kate, the IMEA regional director at VisionLabs. \u201cWe designed a beautiful hi-tech device but with enterprise-grade software running on it.\u201d\n\nVisionLabs did not disclose the buyer of its Luna Ace 2 devices \u2013 <em>Biometric Update</em> has reached out to the company for more details. However, the company did note that the UAE plans to use the hardware in its infrastructure. The country has been introducing facial recognition in passport control, police, public transport, banking and <a href=\"https://www.biometricupdate.com/202308/uae-makes-its-single-sign-on-service-the-front-door-for-6k-private-public-services\">other public projects</a>.\n\nThe company <a href=\"https://www.businessemirates.ae/news/uae-property-news/rezident-skolkovo-otkryl-ofis-v-oae/\">opened</a> its office in Dubai in 2020 and has been <a href=\"https://www.biometricupdate.com/202101/visionlabs-and-smart-engines-innovatrics-announce-biometric-onboarding-customer-wins\">working</a> alongside Armenian computer vision firm <a href=\"https://www.biometricupdate.com/companies/smart-engines\">Smart Engines</a> to provide verification solutions for the Emirates NBD, the largest bank in the UAE.\n\nIn July, the company <a href=\"https://www.biometricupdate.com/202307/visionlabs-introduces-anti-deepfake-tech-clinches-deal-for-govt-biometric-system\">introduced</a> its deepfake detection technology with claims that its algorithm\u2019s accuracy rate reaches between 92 and 100 percent, comparable to some of the best in the world.\n\nVisionLabs also said in June it will cooperate with the Russian government on developing technology for the country\u2019s unified biometrics system (UBS). In February, it was <a href=\"https://www.federalregister.gov/documents/2023/02/27/2023-04099/additions-of-entities-to-the-entity-list-revisions-of-entities-on-the-entity-list\">added</a> to the U.S. Department of Commerce Entity List.", "link": "https://www.biometricupdate.com/202308/visionlabs-launches-upgraded-biometric-access-control-terminal-lands-deal-in-uae", "date_published": "2023-08-23T16:41:08.005820+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}, {"source": "http://feeds.feedburner.com/biometricupdate", "title": "Nigeria\u2019s Borno State to capture biometrics of nearly 7k ex-Boko Haram fighters", "description": "<img alt=\"\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" height=\"1365\" src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/06/28184625/digital-identity-scaled.jpg\" width=\"2048\" />\n\t\tThe Commissioner for Information and Internal Security in Nigeria\u2019s North Eastern state of Borno, Usman A. Tar, said over the weekend that a biometric identification process has begun for 6,900 militants of the jihadist terrorist group, Boko Haram, who have dropped their weapons.\n\nThe repentant fighters are undergoing reformation at a rehabilitation center in the state under the Disarmament, Demobilization, Deradicalization, Rehabilitation, Reconciliation and Reintegration (DDDRRR) program involving different stakeholders.\n\nA <a href=\"https://www.rfi.fr/en/international-news/20230411-inside-nigeria-s-centres-for-jihadists-and-their-captives\" rel=\"noopener\" target=\"_blank\">report</a> which highlights an investigation by AFP reveals that there have been issues with the identification and screening process for some of the persons living in temporary rehabilitation camps.\n\nIn a statement cited by <a href=\"https://punchng.com/borno-resumes-biometrics-capturing-of-6900-repentant-terrorists/\" rel=\"noopener\" target=\"_blank\">Punch</a>, Tar said the identification process is taking place in six batches, and is conducted by a special team of IT\u00a0 and security experts to ensure confidentiality of the fingerprint biometrics and other data captured.\n\nBoko Haram terrorism started in Borno in 2009. The state remains the most badly hit by the insurgency which has killed an estimated 35,000+ people in Nigeria alone.\n\nMeanwhile, HumAngle <a href=\"https://humanglemedia.com/uproar-at-holding-pen-for-surrendered-boko-haram-terrorists-triggered-by-poor-planning/\" rel=\"noopener\" target=\"_blank\">reports</a> that a protest by some of the repentant fighters on Friday August 18, disrupted the biometric registration process at a capture center.\n\nThe outlet mentions that the protesters blocked roads and chanted songs decrying their poor living conditions and slow reintegration into mainstream society.\n\nIt also quoted Tar as assuring that the situation, which he said was created by a miscommunication, had been handled, and the biometric capture process would go on as planned.\n\nNigeria's previous government cited an improved <a href=\"https://www.biometricupdate.com/202105/nigerian-president-says-digital-id-project-will-help-curb-insecurity\">capacity to handle national security threats</a> as one of its motivations for carrying out the country's universal identification project.", "link": "https://www.biometricupdate.com/202308/nigerias-borno-state-to-capture-biometrics-of-nearly-7k-ex-boko-haram-fighters", "date_published": "2023-08-23T14:41:03.979012+00:00", "persistent": false, "dead": false, "artist": null, "album": null, "user": null, "language": "en-US", "thumbnail": null}]