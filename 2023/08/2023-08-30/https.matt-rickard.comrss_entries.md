# Source:Matt Rickard, URL:https://matt-rickard.com/rss, language:en-US

## Llama 2 in the Browser
 - [https://matt-rickard.com/llama-2-in-the-browser](https://matt-rickard.com/llama-2-in-the-browser)
 - RSS feed: https://matt-rickard.com/rss
 - date published: 2023-08-30T13:40:01.947923+00:00

Back in May, I got Vicuna 7B — a chat-tuned version of the original Llama model, working entirely in the browser via the new WebGPU APIs that had shipped in Chrome. I open-sourced a React library to make it easy to use (react-llm).

Today, I’m releasing an updated version of this on Thiggle, which supports Llama 2 Chat in the 7B and 13B variations, as well as Vicuna 7B and Redpajama 3B. The interface is updated for more advanced use cases — allowing you to modify the different parameters in gene

