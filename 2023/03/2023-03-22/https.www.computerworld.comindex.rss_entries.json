[{"source": "https://www.computerworld.com/index.rss", "title": "Q&A: Univ. of Phoenix CIO says chatbots could threaten innovation", "description": "<article>\n\t<section class=\"page\">\n<p>The emergence\u00a0of\u00a0artificial intelligence (AI) has opened the door to endless opportunities across hundreds\u00a0of\u00a0industries, but privacy continues to be huge concern. The use\u00a0of\u00a0data to inform AI tools can unintentionally reveal sensitive and personal information.</p><p>Chatbots built atop large language models (LLMs) such as GPT-4 hold tremendous promise to reduce the amount of time knowedge workers spend\u00a0summarizing meeting transcripts and online chats, creating presenations and campaigns, performing data analysis and even compiling code. But the technology is far from fully vetted.\u00a0</p><p>As AI tools continue to grow and gain acceptance \u2014 not just within consumer-facing applications such as Microsoft's Bing and <a href=\"https://www.computerworld.com/article/3691112/google-opens-sign-ups-for-its-bard-ai-chatbot.html\">Google's Bard</a> chatbot-powered search engines \u2014 there's a growing concern over data privacy and originality.\u00a0</p><p class=\"jumpTag\"><a href=\"https://www.computerworld.com/article/3691231/qa-univ-of-phoenix-cio-says-chatbots-could-threaten-innovation.html#jump\">To read this article in full, please click here</a></p></section></article>", "link": "https://www.computerworld.com/article/3691231/qa-univ-of-phoenix-cio-says-chatbots-could-threaten-innovation.html#tk.rss_all", "date_published": "2023-03-22 16:29:00+00:00", "persistent": false, "user": null, "language": "en-US"}]