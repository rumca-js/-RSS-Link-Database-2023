# Source:Jeff Kaufmann, URL:https://www.jefftk.com/news.rss, language:en-US

## Milk EA, Casu Marzu EA
 - [https://www.jefftk.com/p/milk-ea-casu-marzu-ea](https://www.jefftk.com/p/milk-ea-casu-marzu-ea)
 - RSS feed: https://www.jefftk.com/news.rss
 - date published: 2023-02-27 08:00:00+00:00

<p><span>

Pretty much everyone starts off drinking milk, and while adult
consumption varies culturally, genetically, and ethically,
if I put milk on my morning bran flakes that's a very neutral
choice around here.  If my breakfast came up in talking with a
friend they might think it was dull, but they wouldn't be surprised
or confused. Some parts of effective altruism are like this: giving
money </span>

<a href="https://www.givewell.org/charities/give-directly/November-2020-version">to
very poor people</a> is, to nearly everyone, intuitively and obviously
good.



<p>

Most of EA, however, is more like cheese.  If you've never heard of
cheese it seems strange and maybe not so good, but at least in the US
most people are familiar with the basic idea.  Distributing <a href="https://www.givewell.org/charities/amf">bednets</a> or <a href="https://www.givewell.org/charities/deworm-world-initiative/August-2022-version">deworming
medication</a>, improving the <a href="https://animalcharityevaluators.org/charity-review/the-humane-league/">treatment
of animals</a>, <a href="https://www.alvea.bio/">developing
vaccines</a>, or trying to reduce the risk of <a href="https://80000hours.org/problem-profiles/nuclear-security/">nuclear
war</a> are mild cheeses like Cheddar or Mozzarella: people will
typically think "that seems good" if you tell them about it, and if
they don't it usually doesn't take long <a href="https://www.lesswrong.com/tag/inferential-distance">to explain</a>.

</p>

<p>  In general, work that anyone can see is really valuable
is more likely to <a href="https://forum.effectivealtruism.org/topics/neglectedness">already
be getting</a> the attention it needs.  This means that people who are
looking hard for what most needs doing are often going to be exploring
approaches that are not obvious, or that initially look bizarre.
Pursuit of impact pushes us toward stranger and stronger cheeses, and
while humanity may discover yet more non-obvious cheeses over time I'm
going to refer to the far end of this continuum as the <a href="https://en.wikipedia.org/wiki/Casu_martzu">casu marzu</a> end,
after the cheese that gets its distinctive flavor and texture from
live maggots that jump as you eat it.  EAs who end up out in this
direction aren't going to be able to explain to their neighbor why
they do what they do, and explaining to an interested family member
probably takes several widely spaced conversations.

</p>

<p>

Sometimes people talk casually as if the weird stuff is longtermist
and the mainstream stuff isn't, but if you look at the range of EA
endeavors the main focus areas of EA all have people working along
this continuum.  A typical person likely easily sees the altruistic
case for "help governments create realistic plans for pandemics" but
not "build <a href="https://forum.effectivealtruism.org/topics/refuges">refuges</a>
to protect a small number of people from global catastrophes"; "give
chickens <a href="https://animalcharityevaluators.org/charity-review/the-humane-league/">better
conditions</a>" but not "determine the relative moral differences
between insects <a href="https://forum.effectivealtruism.org/posts/E7xdBbxqPNLjhrnz6/if-adult-insects-matter-how-much-do-juveniles-matter">of
different ages</a>"; "plan for the economic effects of ChatGPT's
successors" but not "formalize what it means for an agent to <a href="https://www.alignmentforum.org/tag/agent-foundations">have a
goal</a>"; "organize <a href="https://www.givingwhatwecan.org/pledge">pledge</a> drives" but
not "give money <a href="https://www.atlasfellowship.org/">to
promising high schoolers</a>".  And I'd rate these all at most <a href="https://en.wikipedia.org/wiki/Blue_cheese">bleu</a>.

</p>

<p>

I've seen this dynamic compared to <a href="https://en.wikipedia.org/wiki/Motte-and-bailey_fallacy">motte-and-bailey</a>
or <a href="https://en.wikipedia.org/wiki/Bait-and-switch">bait-and-switch</a>.
The idea is that someone presents EA to newcomers and only talks about
the mild cheeses, when that's not actually where most of the
community&#8212;and especially the most highly-engaged
members&#8212;think we should be focusing.  People might then think
they were on board with EA when they actually would find a lot of what
goes on under its banner deeply weird.  I think this is partly fair:
when introducing EA, even to a general audience, I think it's
important not to give the impression that these easy-to-present things
are the totality of EA.  In addition to being misleading, that also
risks people who would be a good fit for the stranger bits bouncing
off.  On the other hand, EA isn't the kind of movement where "on
board" makes much sense.  We're not about signing onto a large body of
thought, or expecting everyone within the movement to think everyone
else's work is valuable.  We're united by a <a href="https://forum.effectivealtruism.org/posts/FpjQMYQmS3rWewZ83/effective-altruism-is-a-question-not-an-ideology">common
question</a>, how we can each do the most good, along with culture and
intellectual tools for approaching this question.

</p>

<p>

I think it's really good that EA is open to the very weird, the
mainstream, and everything in between.  One of the more valuable
things that EA provides, however, is intellectual company for people
who are, despite often working in very different fields, pushing down this
fundamentally lonely path away from what everyone can see is good.

 </p>

<p><i>Comment via: <a href="https://www.facebook.com/jefftk/posts/pfbid0LWxkauHMCZemP3mvac46z7FZRVNboWpUPNCqLZKC3wWCx1iK6TLHVTQJxBb4VXDyl">facebook</a>, <a href="https://lesswrong.com/posts/29xpPQ6SnB945dtuH">lesswrong</a>, <a href="https://forum.effectivealtruism.org/posts/LDiStRpF2HSvbgPks">the EA Forum</a>, <a href="https://mastodon.mit.edu/@jefftk/109937056193427652">mastodon</a></i></p>

